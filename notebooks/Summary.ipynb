{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b86177e",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78e0b2",
   "metadata": {},
   "source": [
    "1. Web scraping was done on domain.com.au to obtain listing level data. A public endpoint was utilised that returned a json payload with all the required information about the current listed porperty such as price, name, address, bed, bath...etc. Further external data was also obtained from these listings such as neighbourhood statistics, distribution of age around the area, and a list of closest schools with distance. Overall, 3 dataset was obtained from domain. Roughly 15,000 instances was obtained from scraping domain.\n",
    "\n",
    "2. This data was further cleaned after it was obtained. There were many missing rows as those website listings has not been populated with data yet as of the time of scraping, and were dropped as a result. The rest of the cleaning process follows smoothly with simple tasks such as typecasting columns and splitting information such as the Suburb/Postcode from the address data.\n",
    "\n",
    "3. Suburb level data was obtained from the ABS. These include Median Rental Price per week from 2000 up until 2021, socio-economic-data for 2011,2016,2021 and Age distribution data. Median Rental Price was truncated to 2011-2021 as we planned to use 10 years worth of data for training our model, this dataset was also split into 6 different categories inorder to control for property types as a confounding variable on median price. In terms of Socio-Economic data, since the ABS only collected this information on a 5 year basis, we had alot of missing data for the years that are not 2011,2016,2021. Simple Linear Regression Imputation was chosen as the imputation technique over other simpler techniques such as median or mean imputation. This was chosen as there seems to be an increasing linear trend in socio-economic-features (and its a known fact that features such as Median personal Income increases overtime) and thus in theory Regression Imputation might be able to retain some of the true variation in data for the missing values, as compared to other techniques. Simple Regression was chosen over Multiple Regression as it was deemed unnecessary to impute a data base on more than just years as the regressor. Multiple Regressor would potentially introduce more noise into the data since randomise vector of initial inputs would be required to kickstart our imputation phase. Suburbs with no available data for any years were removed as linear imputation was not possible.\n",
    "\n",
    "4. More external datasets were then obtained along the way, namely Crime Statistics and Population data for the prediction model. As Crime Statistics was available between 2013-2021, we have decided to further reduce our training timeframe from 2011-2021 to 2013-2021. The two datasets were then joined with the aforementioned time series data. After removing all categorical variables, Pearson's Correlation matrix was created to visualise any strong moving trends between features and Median Rental Price. This was used with our own judgement to further remove unnecessary features from our prediction dataset. The final prediction dataset contains Median_age_persons, Median_tot_prsnl_inc_weekly, Average_household_size, Population, Alleged Offender Incident Rate, Victimization Rate, Offender Count.\n",
    "\n",
    "5. Support Vector Regression was the first that came to our mind as the model of choice since our data has many dimensions, and doesn't exactly have a huge number of instances (roughly 90 suburbs after cleaning). SVR can also predict continuous data and thus was perfect for Median Rental Price prediction. We attempted to hyperparameter tune our model, however, as GridSearchCV was extremely computationally expensive, we arrived at a hyperparameter set that wasnt obtained through exhaustive search.\n",
    "\n",
    "\n",
    "6. SVR gave us Median Rental Price from 2022-2027 as specified, this forecasted data, including the forecasted data for the features were used to create visualisation and analysis shown in the presentation slide."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
